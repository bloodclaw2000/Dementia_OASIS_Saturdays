{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6FRa8DENWwL8NfLJ5tYKr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bloodclaw2000/Dementia_OASIS_Saturdays/blob/main/dementia%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rww1GjjtoynD",
        "outputId": "ee54837d-f297-4e32-d7bf-f16f852a271e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dementia_OASIS_Saturdays'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'Dementia_OASIS_Saturdays'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/usr/local/lib/python3.11/dist-packages/') #We need to upgrade Python Client for some reason COLAB is py 3.6\n",
        "\n",
        "#!python -m pip install --upgrade pip\n",
        "!git clone https://github.com/bloodclaw2000/Dementia_OASIS_Saturdays.git\n",
        "%cd Dementia_OASIS_Saturdays"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir params\n",
        "%mkdir nn\n",
        "%mkdir dataset\n"
      ],
      "metadata": {
        "id": "wDeaDgqbspmE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import sys\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import _pickle as cPickle\n",
        "import bz2\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from tabulate import tabulate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from IPython.display import Image\n",
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "hB0gXoFvr-1c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle_aux import pet_load,decompress_pickle,pet_save\n",
        "from dementia_network_class import Dementia,train, getOutput\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "tnCzQkXjpWlE",
        "outputId": "231c34ad-b914-498f-cf0d-aa9de226af23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pickle_aux'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7ffdac9ca263>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpickle_aux\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpet_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecompress_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpet_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdementia_network_class\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDementia\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pickle_aux'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiprocessing.set_start_method('spawn', force=True) #kinda important mostly for CPU\n",
        "\n",
        "device = torch.device(\n",
        "                                        f'cuda:{torch.cuda.current_device()}'\n",
        "                                        if torch.cuda.is_available()\n",
        "                                        else 'cpu')"
      ],
      "metadata": {
        "id": "mebdeb92sXOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_pickle_directory = \"save_dict3\"\n",
        "if not os.path.exists('{0}_decompressed.p'.format(compressed_pickle_directory)):\n",
        "    def force_dementia(dictionary):\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if dictionary[key][key2]['CDR'] == '':\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "                            elif float(dictionary[key][key2]['CDR']) > 0:\n",
        "                                      dictionary[key][key2]['Dementia'] = 1\n",
        "                            else:\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "              return dictionary\n",
        "\n",
        "    def removeyoung(dictionary, age):\n",
        "              dic_pacientes_viejos = {}\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if int(dictionary[key][key2]['Age']) >= age:\n",
        "                                      dic_pacientes_viejos[key] = dictionary[key]\n",
        "              return dic_pacientes_viejos\n",
        "\n",
        "    tmp_dict = decompress_pickle('{0}.pbz2'.format(compressed_pickle_directory))\n",
        "    tmp_dict = force_dementia(tmp_dict) #esto es la funcion del init\n",
        "    tmp_dict = removeyoung(tmp_dict, 59)\n",
        "    tmp_dict = {int(key): value for key, value in tmp_dict.items()}\n",
        "    new_dict = {}\n",
        "    current_index = 0\n",
        "    for key in sorted(tmp_dict.keys()):\n",
        "                        new_dict[current_index] = tmp_dict[key]\n",
        "                        current_index += 1\n",
        "    tmp_dict = new_dict\n",
        "\n",
        "    pet_save(tmp_dict,'{0}_decompressed.p'.format(compressed_pickle_directory))\n",
        "else:\n",
        "     tmp_dict=pet_load('{0}_decompressed.p'.format(compressed_pickle_directory))\n"
      ],
      "metadata": {
        "id": "cseOO1XLpjCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_device(device)\n",
        "\n",
        "print(device)\n",
        "\n",
        "print(f\" Using {device} in this run\")\n",
        "\n",
        "obj = Dementia(dictionary=tmp_dict,device=device)\n"
      ],
      "metadata": {
        "id": "cLOP5NcVp7Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos setear los parámetros para el entrenamiento aquí:\n",
        "obj.setParam('image_type','T88_111')\n",
        "obj.setParam('image_number',1)\n"
      ],
      "metadata": {
        "id": "Vgr8pRKMsKL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropparameters(dataframe, keys = []):\n",
        "    d2 = dataframe\n",
        "    for key in keys:\n",
        "        d2 = d2.drop(key,axis = 1)\n",
        "    return d2\n",
        "def runrandomforest(file_path, Paramsfile = ['ID', 'SES','CDR','Delay','USE','Hand','MMSE']):\n",
        "    Paramsfile.append('Dementia')\n",
        "\n",
        "    source_df = pd.read_csv('results.csv')\n",
        "    source_df['M/F'] = source_df['M/F'].map({'F':1, 'M':0})\n",
        "    df_train = source_df[source_df['USE'] == 'T']\n",
        "    df_test = source_df[source_df['USE'] != 'T']\n",
        "    X_train = dropparameters(df_train,Paramsfile)\n",
        "    X_test =  dropparameters(df_test,Paramsfile)\n",
        "    y_train = df_train['Dementia']\n",
        "    y_test = df_test['Dementia']\n",
        "    #print(list(X_train.columns))\n",
        "    param_dist = {'n_estimators': np.random.randint(50,500,10),\n",
        "              'max_depth': np.random.randint(2,10,4)}\n",
        "    print(param_dist)\n",
        "    rf = RandomForestClassifier()\n",
        "    rand_search = RandomizedSearchCV(rf,\n",
        "                                 param_distributions = param_dist,\n",
        "                                 n_iter=5,\n",
        "                                 cv=5)\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    print('Best hyperparameters:',  rand_search.best_params_)\n",
        "    clf = rand_search.best_estimator_\n",
        "    #clf = tree.DecisionTreeClassifier(max_depth = maxdepth)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    fn=X_train.columns\n",
        "    #♣cn=X_train.columns\n",
        "\n",
        "    for i in range(3):\n",
        "        fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (4,4), dpi = 600)\n",
        "        tree.plot_tree(clf.estimators_[i],\n",
        "                       feature_names = fn,\n",
        "                       class_names = ['healthy','demented'],\n",
        "                       filled = True,\n",
        "                       impurity = True\n",
        "                       );\n",
        "        fig.savefig(f'plottreefncn{i}.png')\n",
        "        plt.figure()\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
        "    plt.show()\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    # Create a series containing feature importances from the model and feature names from the training data\n",
        "    feature_importances = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    plt.show()\n",
        "    # Plot a simple bar chart\n",
        "    feature_importances.plot.bar()\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    return df_train,df_test\n"
      ],
      "metadata": {
        "id": "LjddxO7_sLmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(obj,'params/',['T88','FSL','RAW_1','RAW_2','RAW_3'])\n",
        "\n",
        "print(\"aa\")\n",
        "# getOutput('nn/',['T88'])\n",
        "# getOutput('nn/',['T88','FSL'])\n",
        "#getOutput('nn/',['T88','FSL','RAW_1','RAW_2','RAW_3'])\n",
        "TreeParamsDrop= ['ID', 'SES','CDR','Delay','USE','Hand','Age','M/F','MMSE','eTIV','ASF','nWBV','Educ'] #only images\n",
        "#TreeParamsDrop= ['ID', 'SES','CDR','Delay','USE','Hand','MMSE','PRED_FSL', 'PRED_RAW_1', 'PRED_RAW_2', 'PRED_RAW_3', 'PRED_T88'] #for testing without image predictions\n",
        "#aa,ab = runrandomforest('results.csv', Paramsfile = TreeParamsDrop)"
      ],
      "metadata": {
        "id": "Hgku391usRVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}