{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQ/TuKkinX+aFy38ZUnOU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bloodclaw2000/Dementia_OASIS_Saturdays/blob/main/dementia%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forzamos una versión de Python más nueva y clonamos el repositorio de GitHub para los archivos python"
      ],
      "metadata": {
        "id": "1J4J29PUzc0k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rww1GjjtoynD",
        "outputId": "faed0faf-df16-4417-9d2e-0ac839e27082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Dementia_OASIS_Saturdays' already exists and is not an empty directory.\n",
            "/content/Dementia_OASIS_Saturdays\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "import sys\n",
        "sys.path.insert(0, '/usr/local/lib/python3.11/dist-packages/') #We need to upgrade Python Client for some reason COLAB is py 3.6\n",
        "\n",
        "#!python -m pip install --upgrade pip\n",
        "!git clone https://github.com/bloodclaw2000/Dementia_OASIS_Saturdays.git\n",
        "%cd Dementia_OASIS_Saturdays"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos las carpetas para guardar las redes neuronales, los datasets y las figuras"
      ],
      "metadata": {
        "id": "4iq5tFawzjtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir nn\n",
        "%mkdir dataset\n",
        "%mkdir plots"
      ],
      "metadata": {
        "id": "wDeaDgqbspmE",
        "outputId": "036f961b-a34e-4e16-847a-c201a041cea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘nn’: File exists\n",
            "mkdir: cannot create directory ‘dataset’: File exists\n",
            "mkdir: cannot create directory ‘plots’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las librerias"
      ],
      "metadata": {
        "id": "ToL4p8pJzxQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import sys\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import _pickle as cPickle\n",
        "import bz2\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from tabulate import tabulate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from IPython.display import Image\n",
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "hB0gXoFvr-1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las funciones necesarias desde nuestros programas python"
      ],
      "metadata": {
        "id": "ak2X7spQzzlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle_aux import pet_load, decompress_pickle, pet_save\n",
        "from dementia_network_class import Dementia, train_nn, getOutput\n",
        "from dementia_tree_class import train_tree,  Customtree\n",
        "\n"
      ],
      "metadata": {
        "id": "tnCzQkXjpWlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Version 1.9.1 of Project\n",
        "28/05/2024**\n"
      ],
      "metadata": {
        "id": "whLwXtYB1HjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos CPU o GPU dependiendo de lo que haya"
      ],
      "metadata": {
        "id": "rlgOPJiaz3BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiprocessing.set_start_method('spawn', force=True) #kinda important mostly for CPU\n",
        "\n",
        "device = torch.device(\n",
        "                                        f'cuda:{torch.cuda.current_device()}'\n",
        "                                        if torch.cuda.is_available()\n",
        "                                        else 'cpu')"
      ],
      "metadata": {
        "id": "mebdeb92sXOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el diccionario y generamos uno nuevo limpio sin comprimir"
      ],
      "metadata": {
        "id": "COByid_Kz7g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_pickle_directory = \"save_dict3\"\n",
        "if not os.path.exists('{0}_decompressed.p'.format(compressed_pickle_directory)):\n",
        "    def force_dementia(dictionary):\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if dictionary[key][key2]['CDR'] == '':\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "                            elif float(dictionary[key][key2]['CDR']) > 0:\n",
        "                                      dictionary[key][key2]['Dementia'] = 1\n",
        "                            else:\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "              return dictionary\n",
        "\n",
        "    def removeyoung(dictionary, age):\n",
        "              dic_pacientes_viejos = {}\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if int(dictionary[key][key2]['Age']) >= age:\n",
        "                                      dic_pacientes_viejos[key] = dictionary[key]\n",
        "              return dic_pacientes_viejos\n",
        "\n",
        "    tmp_dict = decompress_pickle('{0}.pbz2'.format(compressed_pickle_directory))\n",
        "    tmp_dict = force_dementia(tmp_dict) #esto es la funcion del init\n",
        "    tmp_dict = removeyoung(tmp_dict, 59)\n",
        "    tmp_dict = {int(key): value for key, value in tmp_dict.items()}\n",
        "    new_dict = {}\n",
        "    current_index = 0\n",
        "    for key in sorted(tmp_dict.keys()):\n",
        "                        new_dict[current_index] = tmp_dict[key]\n",
        "                        current_index += 1\n",
        "    tmp_dict = new_dict\n",
        "\n",
        "    pet_save(tmp_dict,'{0}_decompressed.p'.format(compressed_pickle_directory))\n",
        "else:\n",
        "     tmp_dict=pet_load('{0}_decompressed.p'.format(compressed_pickle_directory))\n"
      ],
      "metadata": {
        "id": "cseOO1XLpjCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forzamos el device y generamos un objeto de todas las redes neuronales"
      ],
      "metadata": {
        "id": "O_d_9dsh0BAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_device(device)\n",
        "\n",
        "print(device)\n",
        "\n",
        "print(f\" Using {device} in this run\")\n",
        "\n",
        "obj = Dementia(dictionary=tmp_dict,device=device)\n",
        "logpath = 'logs/'\n"
      ],
      "metadata": {
        "id": "cLOP5NcVp7Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seteamos los parámetros manualmente que queramos, también hay archivos txt en params"
      ],
      "metadata": {
        "id": "6V_fF1Rz0GzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos setear los parámetros para el entrenamiento aquí:\n",
        "obj.setParam('image_type','T88_111')\n",
        "obj.setParam('image_number',1)\n"
      ],
      "metadata": {
        "id": "Vgr8pRKMsKL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos cada red neuronal con el tipo de imagenes que queramos y creamos los datasets"
      ],
      "metadata": {
        "id": "f__rKWY70LME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train(obj,'params/',['T88'])\n",
        "# train(obj,'params/',['T88','FSL'])\n",
        "train_nn(obj, 'params_nn/', ['T88', 'FSL', 'RAW_1', 'RAW_2', 'RAW_3'],logpath = logpath)\n",
        "\n",
        "# getOutput('nn/',['T88'])\n",
        "# getOutput('nn/',['T88','FSL'])\n",
        "getOutput('nn/', ['T88', 'FSL', 'RAW_1', 'RAW_2', 'RAW_3'],device = device)\n"
      ],
      "metadata": {
        "id": "LjddxO7_sLmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora entrenamos el random_forest"
      ],
      "metadata": {
        "id": "fHL_d2UN0RBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_df = pd.read_csv('results.csv')\n",
        "treeclass = Customtree(source_df)\n",
        "#treeclass.write_dict_to_file('params_tree/treeparam.txt')\n",
        "train_tree(treeclass,'params_tree/treeparam.txt')\n"
      ],
      "metadata": {
        "id": "Hgku391usRVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}