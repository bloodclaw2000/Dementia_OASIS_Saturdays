{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwLpxAQ77FQZpQyyCNz+DF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bloodclaw2000/Dementia_OASIS_Saturdays/blob/main/dementia%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rww1GjjtoynD",
        "outputId": "74294285-b34e-492b-d873-7eb0b21527d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dementia_OASIS_Saturdays'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 66 (delta 11), reused 47 (delta 9), pack-reused 10\u001b[K\n",
            "Receiving objects: 100% (66/66), 135.34 MiB | 25.07 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/Dementia_OASIS_Saturdays\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/usr/local/lib/python3.11/dist-packages/') #We need to upgrade Python Client for some reason COLAB is py 3.6\n",
        "\n",
        "#!python -m pip install --upgrade pip\n",
        "!git clone https://github.com/bloodclaw2000/Dementia_OASIS_Saturdays.git\n",
        "%cd Dementia_OASIS_Saturdays"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir nn\n",
        "%mkdir dataset\n"
      ],
      "metadata": {
        "id": "wDeaDgqbspmE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import sys\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import _pickle as cPickle\n",
        "import bz2\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from tabulate import tabulate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from IPython.display import Image\n",
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "hB0gXoFvr-1c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle_aux import pet_load, decompress_pickle, pet_save\n",
        "from dementia_network_class import Dementia, train_nn, getOutput\n",
        "from dementia_tree_class import train_tree,  Customtree\n",
        "\n"
      ],
      "metadata": {
        "id": "tnCzQkXjpWlE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiprocessing.set_start_method('spawn', force=True) #kinda important mostly for CPU\n",
        "\n",
        "device = torch.device(\n",
        "                                        f'cuda:{torch.cuda.current_device()}'\n",
        "                                        if torch.cuda.is_available()\n",
        "                                        else 'cpu')"
      ],
      "metadata": {
        "id": "mebdeb92sXOj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_pickle_directory = \"save_dict3\"\n",
        "if not os.path.exists('{0}_decompressed.p'.format(compressed_pickle_directory)):\n",
        "    def force_dementia(dictionary):\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if dictionary[key][key2]['CDR'] == '':\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "                            elif float(dictionary[key][key2]['CDR']) > 0:\n",
        "                                      dictionary[key][key2]['Dementia'] = 1\n",
        "                            else:\n",
        "                                      dictionary[key][key2]['Dementia'] = 0\n",
        "              return dictionary\n",
        "\n",
        "    def removeyoung(dictionary, age):\n",
        "              dic_pacientes_viejos = {}\n",
        "              for key in dictionary:\n",
        "                        for key2 in dictionary[key]:\n",
        "                            if int(dictionary[key][key2]['Age']) >= age:\n",
        "                                      dic_pacientes_viejos[key] = dictionary[key]\n",
        "              return dic_pacientes_viejos\n",
        "\n",
        "    tmp_dict = decompress_pickle('{0}.pbz2'.format(compressed_pickle_directory))\n",
        "    tmp_dict = force_dementia(tmp_dict) #esto es la funcion del init\n",
        "    tmp_dict = removeyoung(tmp_dict, 59)\n",
        "    tmp_dict = {int(key): value for key, value in tmp_dict.items()}\n",
        "    new_dict = {}\n",
        "    current_index = 0\n",
        "    for key in sorted(tmp_dict.keys()):\n",
        "                        new_dict[current_index] = tmp_dict[key]\n",
        "                        current_index += 1\n",
        "    tmp_dict = new_dict\n",
        "\n",
        "    pet_save(tmp_dict,'{0}_decompressed.p'.format(compressed_pickle_directory))\n",
        "else:\n",
        "     tmp_dict=pet_load('{0}_decompressed.p'.format(compressed_pickle_directory))\n"
      ],
      "metadata": {
        "id": "cseOO1XLpjCr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_device(device)\n",
        "\n",
        "print(device)\n",
        "\n",
        "print(f\" Using {device} in this run\")\n",
        "\n",
        "obj = Dementia(dictionary=tmp_dict,device=device)\n"
      ],
      "metadata": {
        "id": "cLOP5NcVp7Zb",
        "outputId": "a9cf05fe-a62e-4d8a-e2b8-6c4e9c79c6c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            " Using cpu in this run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos setear los parámetros para el entrenamiento aquí:\n",
        "obj.setParam('image_type','T88_111')\n",
        "obj.setParam('image_number',1)\n"
      ],
      "metadata": {
        "id": "Vgr8pRKMsKL2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train(obj,'params/',['T88'])\n",
        "# train(obj,'params/',['T88','FSL'])\n",
        "train_nn(obj, 'params_nn/', ['T88', 'FSL', 'RAW_1', 'RAW_2', 'RAW_3'])\n",
        "\n",
        "# getOutput('nn/',['T88'])\n",
        "# getOutput('nn/',['T88','FSL'])\n",
        "getOutput('nn/', ['T88', 'FSL', 'RAW_1', 'RAW_2', 'RAW_3'])\n"
      ],
      "metadata": {
        "id": "LjddxO7_sLmO",
        "outputId": "9b730cb7-2756-4107-a921-5fdc2be6feeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read parameters dictionary at relative location params_nn/RAW_1.txt and setting them \n",
            "Param invalid_key does not exist\n",
            "Param does not exist\n",
            "Resetting to default value\n",
            "Now calculating predictions for file params_nn/RAW_1.txt\n",
            "{'plot': 'True', 'image_type': 'RAW', 'image_number': 1, 'patience_validation': 3, 'patience_plateau': 3, 'validation_patience': 3, 'delta_min': 0, 'batch_size': 10, 'split_size': 0.8, 'max_loss_reset': 5, 'learning_rate': 0.0001, 'weight_decay': 0.1, 'nepochs': 1000, 'first_conv_outchann': 6, 'second_conv_outchann': 16, 'fclayer1': 120, 'fclayer2': 'None', 'criterion_type': 'BCElogitsloss', 'optimizer': 'Adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_df = pd.read_csv('results.csv')\n",
        "treeclass = Customtree(source_df)\n",
        "#treeclass.write_dict_to_file('params_tree/treeparam.txt')\n",
        "train_tree(treeclass,'params_tree/treeparam.txt')\n"
      ],
      "metadata": {
        "id": "Hgku391usRVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}